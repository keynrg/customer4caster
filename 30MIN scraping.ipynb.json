{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape(region = 'NSW1'):\n",
    "    #####################################################\n",
    "    # This function will scrape the data through the API#\n",
    "    # and save it to your computer.                     #\n",
    "    #####################################################\n",
    "    \n",
    "    import datetime \n",
    "    import pandas as pd\n",
    "    import requests\n",
    "    import time   \n",
    "    \n",
    "    #1. Request & Scrape\n",
    "    s = requests.Session()\n",
    "    #Some crazy stuff\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/68.0.3440.106 Safari/537.36\", \n",
    "        \"Origin\": \"https://www.aemo.com.au\",\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Host\": \"www.aemo.com.au\",\n",
    "        \"Origin\": \"https://www.aemo.com.au\",\n",
    "        \"Referer\": \"https://www.aemo.com.au/aemo/apps/visualisations/elec-nem-priceanddemand.html\",\n",
    "        \"Sec-Fetch-Mode\": \"cors\",\n",
    "        \"Sec-Fetch-Site\": \"same-origin\"\n",
    "    }\n",
    "\n",
    "    s.headers = headers\n",
    "    json = {\"timeScale\": [\"30MIN\"]}\n",
    "    url = \"https://www.aemo.com.au/aemo/apps/api/report/5MIN\"\n",
    "    response = s.post(url, json=json)\n",
    "    results = response.json()\n",
    "    #Don't mind the following lines, although it shows 5MIN, \n",
    "    #we are actually scraping the 30MIN data.\n",
    "    history = results['5MIN'] \n",
    "\n",
    "    #2. Make dataframe\n",
    "    data = [row.values() for row in history]\n",
    "    columns = history[0].keys()\n",
    "    df = pd.DataFrame(data, columns=columns)\n",
    "    df.index = df['SETTLEMENTDATE']\n",
    "    df = df[df['REGION']== region]\n",
    "    df = df.drop(columns = ['REGIONID', 'REGION','SETTLEMENTDATE', 'REGION'])\n",
    "    #The following line will save the data with its scraping time\n",
    "    df.to_csv(r'/Users/phuongdoan/Desktop/{0}{1}.csv'.format(region, datetime.datetime.now()))\n",
    "    print('Data archieved.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regularScrape(afterSeconds = 1800):\n",
    "    ##################################\n",
    "    #Specify the time to update data.#\n",
    "    ##################################\n",
    "    \n",
    "    import time\n",
    "    import datetime\n",
    "    \n",
    "    while(True):\n",
    "        print(datetime.datetime.now())\n",
    "        scrape()\n",
    "        time.sleep(afterSeconds)\n",
    "        #After this, the loop will pause for afterSeconds seconds\n",
    "        #by default 30 minutes = 1800 seconds unless specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
