{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Armidale_Summer_60steps_Uni.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rDh9dnfr2FUy"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/googlecolab/colabtools/blob/master/notebooks/colab-github-demo.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RusDx9RfG2tl"
      },
      "source": [
        "# Run this before everything\n",
        "!pip install --upgrade --q tensorflow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9chR0vj1G_vn"
      },
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "from pandas import read_csv, to_datetime\n",
        "import numpy as np\n",
        "from numpy import array,hstack\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "plt.rcParams['figure.figsize'] = 10, 5\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "from datetime import datetime\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLrIkJ1QHB2-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88eb8328-353c-4e6b-99b1-51f75519a327"
      },
      "source": [
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gK5OjKxSHEHO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33df3bbf-9980-4640-aceb-f7906208ea47"
      },
      "source": [
        "cd /content/gdrive/My Drive/KeyEnergy/Armidale/"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/KeyEnergy/Armidale\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbEr2cHYfeJp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "outputId": "3d8eac3a-9111-43ab-99d2-da2d806e4637"
      },
      "source": [
        "ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2017_Armidale.csv\n",
            "2018_Armidale.csv\n",
            "2019_Armidale.csv\n",
            "\u001b[0m\u001b[01;34maiplatformmvp\u001b[0m/\n",
            "Armidale2019_Sim_v1_Harry25Feb.csv\n",
            "Armidale_AutumnHoliday_60steps_2031test.h5\n",
            "Armidale_AutumnHoliday_60steps_20.54test.h5\n",
            "Armidale_AutumnHoliday_60steps_225.h5\n",
            "Armidale.csv\n",
            "Armidale_SpringHoliday_60steps_24.h5\n",
            "Armidale_Summer_12_steps_Mul_14.57.h5\n",
            "Armidale_SummerHoliday_60steps_16.h5\n",
            "Armidale_SummerHoliday_60steps_1746.h5\n",
            "Armidale_SummerHoliday_60steps_18.h5\n",
            "Armidale_WinterHoliday_60steps_28.h5\n",
            "Armidale_WinterHoliday_60steps_30.h5\n",
            "LSTM_Armidale.ipynb\n",
            "Parameters.xlsx\n",
            "public_holiday.csv\n",
            "scaler.save\n",
            "\u001b[01;34msummer30\u001b[0m/\n",
            "terms_date.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-ilP-6aHGkB"
      },
      "source": [
        "# Import the dataset\n",
        "#drop = ['kVAR', 'kW', 'kWh Value','kVARh Value','kWh Actual', 'Max kW','Period', 'No Of Meters', 'kWh Estimate', 'TOU Demand kW', 'TOU Demand kVA', 'PF', 'CO2']\n",
        "datasetAll = read_csv(r'Armidale.csv', header = 0)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_32sJRAeZpjW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad1c4115-b25f-4856-da1c-f4380ae3430b"
      },
      "source": [
        "scaler = MinMaxScaler()\n",
        "scaler.fit(datasetAll[['Demand']])\n",
        "from sklearn.externals import joblib\n",
        "scaler_filename = \"scaler.save\"\n",
        "joblib.dump(scaler, scaler_filename) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['scaler.save']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHGOf1HGd2KI"
      },
      "source": [
        "a = [[0.123, 0.3, 0.4445, 0.666666]]\n",
        "scaler = joblib.load(scaler_filename) \n",
        "a = scaler.inverse_transform(a)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PACnYQIwLp5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "6bab9bc8-c65b-410e-a14d-a092552183ec"
      },
      "source": [
        "scaler.inverse_transform([[0.859315634]])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[291.80296573]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0g3kWh4dlG7B"
      },
      "source": [
        "scaler = joblib.load(\"scaler.save\") "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3OaFZyLoOy-Y"
      },
      "source": [
        "datasetAll\n",
        "su17 = datasetAll.loc[0:5663]\n",
        "au17 = datasetAll.loc[5664:14495]\n",
        "wi17 = datasetAll.loc[14496:23327]\n",
        "sp17 = datasetAll.loc[23328:32059]\n",
        "su18 = datasetAll.loc[32060:40699]\n",
        "au18 = datasetAll.loc[40700:49531]\n",
        "wi18 = datasetAll.loc[49532:58363]\n",
        "sp18 = datasetAll.loc[58364:67095]\n",
        "su19 = datasetAll.loc[67096:75735]\n",
        "au19 = datasetAll.loc[75736: 84567]\n",
        "wi19 = datasetAll.loc[84568: 93399]\n",
        "sp19 = datasetAll.loc[93400:102131]\n",
        "su20 = datasetAll.loc[102132:]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0240aDeh0pZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "ccfce354-b774-432b-b23b-3f0952c2a0d8"
      },
      "source": [
        "datasetAll.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Time</th>\n",
              "      <th>Demand</th>\n",
              "      <th>Temp</th>\n",
              "      <th>isWeekend</th>\n",
              "      <th>isNotSchoolTerm</th>\n",
              "      <th>isHoliday</th>\n",
              "      <th>isNotSchoolOrHoliday</th>\n",
              "      <th>Demand_scaled</th>\n",
              "      <th>Temp_scaled</th>\n",
              "      <th>Out</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1/1/17</td>\n",
              "      <td>0:00:00</td>\n",
              "      <td>62.861</td>\n",
              "      <td>23.8</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.185116</td>\n",
              "      <td>0.692671</td>\n",
              "      <td>0.185116</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1/1/17</td>\n",
              "      <td>0:15:00</td>\n",
              "      <td>66.649</td>\n",
              "      <td>23.8</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.196271</td>\n",
              "      <td>0.692671</td>\n",
              "      <td>0.196271</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1/1/17</td>\n",
              "      <td>0:30:00</td>\n",
              "      <td>73.032</td>\n",
              "      <td>23.8</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.215068</td>\n",
              "      <td>0.692671</td>\n",
              "      <td>0.215068</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1/1/17</td>\n",
              "      <td>0:45:00</td>\n",
              "      <td>90.737</td>\n",
              "      <td>23.8</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.267207</td>\n",
              "      <td>0.692671</td>\n",
              "      <td>0.267207</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1/1/17</td>\n",
              "      <td>1:00:00</td>\n",
              "      <td>86.345</td>\n",
              "      <td>23.3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.254273</td>\n",
              "      <td>0.680851</td>\n",
              "      <td>0.254273</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Date     Time  Demand  ...  Demand_scaled  Temp_scaled       Out\n",
              "0  1/1/17  0:00:00  62.861  ...       0.185116     0.692671  0.185116\n",
              "1  1/1/17  0:15:00  66.649  ...       0.196271     0.692671  0.196271\n",
              "2  1/1/17  0:30:00  73.032  ...       0.215068     0.692671  0.215068\n",
              "3  1/1/17  0:45:00  90.737  ...       0.267207     0.692671  0.267207\n",
              "4  1/1/17  1:00:00  86.345  ...       0.254273     0.680851  0.254273\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2iT8lsHtHl8r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec11ab18-6f4d-40d6-de15-61b7fcb44ca4"
      },
      "source": [
        "def split_dataset(dataset, test_fraction = 0.2):\n",
        "  ## Split the dataset into train and test set ##\n",
        "  train_size = int(len(dataset) * (1 - test_fraction))\n",
        "  train_data, test_data = dataset.loc[:train_size], dataset.loc[train_size:]\n",
        "  return train_data, test_data\n",
        "\n",
        "def split_sequence(sequence, n_steps_in, n_steps_out):\n",
        "\t## Split a univariate sequence into samples ##\n",
        "\tX, y = list(), list()\n",
        "\tfor i in range(len(sequence)):\n",
        "\t\t# find the end of this pattern\n",
        "\t\tend_ix = i + n_steps_in\n",
        "\t\tout_end_ix = end_ix + n_steps_out\n",
        "\t\t# check if we are beyond the sequence\n",
        "\t\tif out_end_ix > len(sequence):\n",
        "\t\t\tbreak\n",
        "\t\t# gather input and output parts of the pattern\n",
        "\t\tseq_x, seq_y = sequence[i:end_ix], sequence[end_ix:out_end_ix]\n",
        "\t\tX.append(seq_x)\n",
        "\t\ty.append(seq_y)\n",
        "\treturn array(X), array(y)\n",
        " \n",
        "import tensorflow\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras import *\n",
        "print(tensorflow.__version__)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LnSv1Nq3J0cw"
      },
      "source": [
        "n_steps_in= 30\n",
        "n_steps_out = 32\n",
        "\n",
        "whichSeason = 0 \n",
        "# split dataset into train and test set\n",
        "train, test = split_dataset(su17.append(su18, ignore_index=True).append(su19, ignore_index=True).append(su20, ignore_index = True), test_fraction= 0.2)\n",
        "\n",
        "demand_scaler = MinMaxScaler()\n",
        "train['Demand_scaled'] = demand_scaler.fit_transform(train[['Demand']])\n",
        "test['Demand_scaled'] = demand_scaler.transform(test[['Demand']])\n",
        "# split into samples\n",
        "X_train, y_train = split_sequence(train['Demand_scaled'].values, n_steps_in, n_steps_out)\n",
        "X_test, y_test = split_sequence(test['Demand_scaled'].values, n_steps_in, n_steps_out)\n",
        "\n",
        "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
        "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OyO6X51fJnDN"
      },
      "source": [
        "def build_model(X_train, y_train, X_test, y_test, n_steps_in, n_steps_out, epochs, verbose): \n",
        "  ## Build an LSTM model ##\n",
        "    # Define model\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(20, activation='relu', return_sequences= 1, input_shape=(n_steps_in, 1)))\n",
        "    model.add(Dropout(0.02))\n",
        "    model.add(LSTM(20, return_sequences= 1))\n",
        "    model.add(Dropout(0.05))\n",
        "    model.add(LSTM(20, return_sequences = 0))\n",
        "    \n",
        "    model.add(Dense(n_steps_out)) \n",
        "    \n",
        "    # Train Model\n",
        "    model.compile(optimizer='adam', loss='mse')\n",
        "    history = model.fit(X_train, y_train, epochs=epochs, verbose=verbose, validation_split= 0.2, shuffle = False ,callbacks = [EarlyStopping(patience = 10)])\n",
        "    \n",
        "    # Visualise Epoch\n",
        "    plt.plot(history.history['loss'], label='loss')\n",
        "    plt.plot(history.history['val_loss'], label='val_loss')\n",
        "    plt.legend()\n",
        "\n",
        "    return model, history\n",
        "\n",
        "model, history = build_model(X_train, y_train, X_test, y_test, n_steps_in = n_steps_in, n_steps_out = n_steps_out, epochs = 100, verbose = 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_oZtB9iM6Ks"
      },
      "source": [
        "def RMSE(model, X_test, y_test, n_steps_out, scaler):\n",
        "  y_hat = scaler.inverse_transform(model.predict(X_test))\n",
        "  RMSE = np.sqrt(mean_squared_error(scaler.inverse_transform(y_test.reshape(y_hat.shape[0], y_hat.shape[1])), y_hat, multioutput= 'raw_values'))\n",
        "  mean_RMSE = sum(RMSE)/ n_steps_out  \n",
        "  return y_hat, RMSE, mean_RMSE\n",
        "y_hat_train, train_RMSE, train_mean_RMSE =RMSE(model, X_train, y_train, n_steps_out, demand_scaler)\n",
        "y_hat,RMSE, mean_RMSE = RMSE(model, X_test, y_test, n_steps_out, demand_scaler)\n",
        "print(\"Train\")\n",
        "print(train_RMSE, train_mean_RMSE)\n",
        "print(\"Test\")\n",
        "print(RMSE, mean_RMSE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9TCUhcA37Ui3"
      },
      "source": [
        "import random\n",
        "# need to take into account that the in mul model\n",
        "def shifting_plot(y_hat, y_test, scaler, specific_plot = -1):\n",
        "  i = random.randint(0, y_hat.shape[0]-n_steps_out)\n",
        "  end_index = n_steps_out\n",
        "  position_start_index = 0\n",
        "  \n",
        "  plt.figure(figsize=(20,10))\n",
        "  plt.plot(scaler.inverse_transform(y_test.reshape(y_hat.shape[0], y_hat.shape[1]))[i], label = \"Truth\", marker = 'x', alpha = 0.1, color = 'orange', linewidth = 5)\n",
        "\n",
        "  if(specific_plot == -1):\n",
        "    while(end_index > 0):\n",
        "      plt.plot(pd.Series(data = (y_hat.reshape(y_hat.shape[0],y_hat.shape[1])[i])[0:end_index], index = np.arange(n_steps_out)[position_start_index:n_steps_out] ), marker = '4')\n",
        "      i+=1\n",
        "      end_index-=1\n",
        "      position_start_index += 1\n",
        "  else:\n",
        "    plt.plot(pd.Series(data = (y_hat.reshape(y_hat.shape[0],y_hat.shape[1])[i+specific_plot])[0:end_index-specific_plot], index = np.arange(n_steps_out)[position_start_index + specific_plot:n_steps_out] ), marker = '4')  \n",
        "  \n",
        "  \n",
        "  plt.xticks(np.arange(n_steps_out), array([str(n) for n in range(1,n_steps_out+1)]))\n",
        "  plt.xlabel(\"nth step in the future\")\n",
        "  plt.legend()\n",
        "  plt.ylabel(\"kVA\")\n",
        "  plt.show()\n",
        "\n",
        "shifting_plot(y_hat, y_test, demand_scaler, -1 )\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jM9Xw8YymHc9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99c9f014-d9ef-4216-fc04-17dc42948ac7"
      },
      "source": [
        "cd Demands_Model/Armidale/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/KeyEnergy/Armidale/Demands_Model/Armidale\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00-vDZGG2ZOK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "107186e0-2430-4310-c8e7-57a2056b269d"
      },
      "source": [
        "model.save('Armidale_20210128_1230_in30out32_summer_RMSE22')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: Armidale_20210128_1230_in30out32_summer_RMSE22/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: Armidale_20210128_1230_in30out32_summer_RMSE22/assets\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}
